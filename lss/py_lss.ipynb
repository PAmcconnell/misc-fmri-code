{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with SPM.mat files in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from os.path import dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_consecutive(index):\n",
    "    ranges = []\n",
    "    for key, group in groupby(enumerate(index),\n",
    "                              lambda (index, item): index - item):\n",
    "        group = map(itemgetter(1), group)\n",
    "        if len(group) > 1:\n",
    "            ranges.append(xrange(group[0], group[-1]))\n",
    "        else:\n",
    "            ranges.append(group[0])\n",
    "    return ranges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_lss_vectors(vectors):\n",
    "    all_names, all_onsets, all_durations = vectors\n",
    "    lss_names = []\n",
    "    lss_onsets = []\n",
    "    lss_durations = []\n",
    "    for i in range(len(all_names)):\n",
    "        temp_all_names = list(all_names)\n",
    "        temp_all_onsets = list(all_onsets)\n",
    "        temp_all_durations = list(all_durations)\n",
    "        name = temp_all_names.pop(i)\n",
    "        onsets = temp_all_onsets.pop(i)\n",
    "        durations = temp_all_durations.pop(i)\n",
    "        for trial in range(len(onsets)):\n",
    "            trial_name = '{0}_{1}'.format(name, trial)\n",
    "            all_trial_names = [trial_name, name] + temp_all_names\n",
    "            lss_names.append(all_trial_names)\n",
    "\n",
    "            temp_onsets = list(onsets)\n",
    "            onset = temp_onsets.pop(trial)\n",
    "            all_trial_onsets = [[onset], temp_onsets] + temp_all_onsets\n",
    "            lss_onsets.append(all_trial_onsets)\n",
    "\n",
    "            temp_durations = list(durations)\n",
    "            duration = temp_durations.pop(trial)\n",
    "            all_trial_durations = [[duration], temp_durations] + temp_all_durations\n",
    "            lss_durations.append(all_trial_durations)\n",
    "    lss_vectors = [lss_names, lss_onsets, lss_durations]\n",
    "    return lss_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spm_file = '/home/tsalo006/misc-fmri-code/beta-example/first_level/SPM.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LV = sio.loadmat(spm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling 200 timepoints across 2 sessions.\n"
     ]
    }
   ],
   "source": [
    "files = LV['SPM'][0]['xY'][0]['P'][0][0]  # <- one of these may point to run\n",
    "sessions = LV['SPM'][0]['Sess'][0][0]\n",
    "print('Modeling {0} timepoints across {1} sessions.'.format(len(files), len(sessions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find shared filepath across files\n",
    "idx = range(len(files[0]))\n",
    "f0 = np.array(list(files[0]), str)\n",
    "for f in files:\n",
    "    fl = np.array(list(f), str)\n",
    "    min_len = np.min((len(f0), len(fl)))\n",
    "    temp_idx = np.where(f0[:min_len]==fl[:min_len])\n",
    "    idx = np.intersect1d(idx, temp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Impulses_0', u'Impulses'], ['Impulses_1', u'Impulses'], ['Impulses_2', u'Impulses'], ['Impulses_3', u'Impulses'], ['Impulses_4', u'Impulses'], ['Impulses_5', u'Impulses'], ['Impulses_6', u'Impulses'], ['Impulses_7', u'Impulses'], ['Impulses_8', u'Impulses'], ['Impulses_9', u'Impulses']]\n",
      "[['Impulses_0', u'Impulses'], ['Impulses_1', u'Impulses'], ['Impulses_2', u'Impulses'], ['Impulses_3', u'Impulses'], ['Impulses_4', u'Impulses'], ['Impulses_5', u'Impulses'], ['Impulses_6', u'Impulses'], ['Impulses_7', u'Impulses'], ['Impulses_8', u'Impulses'], ['Impulses_9', u'Impulses']]\n"
     ]
    }
   ],
   "source": [
    "idx2 = get_consecutive(idx)\n",
    "shared_str = ''.join([f0[i] for i in idx2])\n",
    "old_path = dirname(shared_str)\n",
    "\n",
    "temp_dir = '/scratch/tsalo006'\n",
    "new_files = [f.replace(old_path, temp_dir) for f in files]\n",
    "new_data_dirs = list(set([dirname(f) for f in new_files]))\n",
    "# for data_dir in new_data_dirs:\n",
    "#     if not isdir(data_dir):\n",
    "#         mkdir(data_dir)\n",
    "# \n",
    "# for i, f in enumerate(files):\n",
    "#     copyfile(f, new_files[i])\n",
    "\n",
    "for i_sess in range(len(sessions)):\n",
    "    row_idx = sessions[i_sess]['row'][0] - 1  # don't forget python zero-indexes\n",
    "    sess_files = [nf for j, nf in enumerate(new_files) if j in row_idx]\n",
    "    covariates = sessions[i_sess]['C'][0]['C'][0]\n",
    "    orig_names = []\n",
    "    orig_onsets = []\n",
    "    orig_durations = []\n",
    "    for cond in sessions[i_sess]['U'][0]:\n",
    "        orig_names.append(cond['name'][0][0][0])\n",
    "        orig_onsets.append(np.squeeze(cond['ons']))\n",
    "        orig_durations.append(np.squeeze(cond['dur']))\n",
    "    params = [orig_names, orig_onsets, orig_durations]\n",
    "    lss_vectors = make_lss_vectors(params)\n",
    "    lss_names, lss_onsets, lss_durations = lss_vectors\n",
    "    print lss_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
